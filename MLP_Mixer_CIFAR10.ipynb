{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MLP-Mixer on CIFAR-10: A Minimalist Vision Transformer Alternative\n",
        "\n",
        "## Introduction\n",
        "\n",
        "Welcome to this comprehensive implementation of **MLP-Mixer**, a novel architecture that challenges the conventional wisdom of vision transformers. This notebook demonstrates a fully-featured training pipeline for the MLP-Mixer model on the CIFAR-10 dataset, showcasing how simple Multi-Layer Perceptrons (MLPs) can achieve competitive performance in computer vision tasks without convolutional layers or attention mechanisms.\n",
        "\n",
        "### What is MLP-Mixer?\n",
        "\n",
        "MLP-Mixer is a groundbreaking architecture introduced by Tolstikhin et al. (2021) that replaces both convolutions and self-attention mechanisms with two types of MLP layers:\n",
        "1. **Token-mixing MLPs**: Operate across spatial locations (per patch)\n",
        "2. **Channel-mixing MLPs**: Operate across channels (per location)\n",
        "\n",
        "This \"mixer\" approach achieves surprisingly strong performance while maintaining architectural simplicity and computational efficiency.\n",
        "\n",
        "### Key Features of This Implementation\n",
        "\n",
        "This notebook provides a production-ready training framework with:\n",
        "\n",
        "- **Complete MLP-Mixer Implementation**: From patch embedding to mixer blocks with residual connections\n",
        "- **Advanced Training Techniques**:\n",
        "  - Mixup data augmentation for improved generalization\n",
        "  - Exponential Moving Average (EMA) for stable training\n",
        "  - Cosine annealing with warmup learning rate scheduling\n",
        "  - AdamW optimizer with weight decay\n",
        "- **Modern PyTorch Practices**:\n",
        "  - `torch.compile()` integration for performance optimization\n",
        "  - TF32 precision support on compatible GPUs\n",
        "  - Efficient data loading with AutoAugment policies\n",
        "- **Comprehensive Evaluation**:\n",
        "  - Precision, recall, F1-score per class\n",
        "  - Confusion matrix visualization\n",
        "  - Model checkpointing and metrics logging\n",
        "\n",
        "### Model Specifications\n",
        "\n",
        "- **Architecture**: Tiny MLP-Mixer (< 1M parameters)\n",
        "- **Input**: 32√ó32 RGB images (CIFAR-10)\n",
        "- **Patch Size**: 4√ó4 (64 patches per image)\n",
        "- **Embedding Dimension**: 160\n",
        "- **Mixer Blocks**: 6 layers\n",
        "- **Token/Channel Hidden Dimensions**: Dynamically scaled\n",
        "\n",
        "### Why This Implementation Matters\n",
        "\n",
        "This notebook serves as both an educational resource and a practical template for:\n",
        "- Understanding the MLP-Mixer architecture in depth\n",
        "- Learning modern PyTorch training best practices\n",
        "- Experimenting with alternative vision architectures\n",
        "- Building a foundation for custom computer vision projects\n",
        "\n",
        "Whether you're a researcher exploring beyond transformers, a practitioner looking for efficient vision models, or a student learning about modern deep learning architectures, this implementation offers valuable insights into minimalist yet powerful approaches to computer vision.\n",
        "\n",
        "Let's dive into the code and explore how simple MLPs can see!"
      ],
      "metadata": {
        "id": "c5jacofbg2rn"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imports"
      ],
      "metadata": {
        "id": "cdwldhvgllHo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import argparse\n",
        "import math\n",
        "import os\n",
        "import random\n",
        "import copy\n",
        "import warnings\n",
        "from typing import Tuple\n",
        "\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets, transforms\n",
        "from tqdm import tqdm\n",
        "\n",
        "# Optional: metrics & visualization\n",
        "try:\n",
        "    import matplotlib.pyplot as plt\n",
        "    import seaborn as sns\n",
        "    from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
        "    MATPLOTLIB_AVAILABLE = True\n",
        "except ImportError:\n",
        "    MATPLOTLIB_AVAILABLE = False\n",
        "    print(\"[Warning] matplotlib/seaborn/sklearn unavailable ‚Äî text-only metrics.\")"
      ],
      "metadata": {
        "id": "pSp9V3xlltRa"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model Definitions"
      ],
      "metadata": {
        "id": "btaMJczYlzAI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class PatchEmbedding(nn.Module):\n",
        "    \"\"\"Linear patch embedding: split image into non-overlapping patches and project to embedding space.\"\"\"\n",
        "    def __init__(self, img_size=32, patch_size=4, in_ch=3, embed_dim=160):\n",
        "        super().__init__()\n",
        "        assert img_size % patch_size == 0, \"img_size must be divisible by patch_size\"\n",
        "        self.patch_size = patch_size\n",
        "        self.num_patches = (img_size // patch_size) ** 2\n",
        "        self.patch_dim = in_ch * patch_size * patch_size\n",
        "        self.proj = nn.Linear(self.patch_dim, embed_dim)\n",
        "\n",
        "    def forward(self, x):\n",
        "        B, C, H, W = x.shape\n",
        "        p = self.patch_size\n",
        "        x = x.unfold(2, p, p).unfold(3, p, p)\n",
        "        x = x.contiguous().view(B, C, H // p, W // p, p * p)\n",
        "        x = x.permute(0, 2, 3, 1, 4).contiguous()\n",
        "        x = x.view(B, -1, self.patch_dim)\n",
        "        x = self.proj(x)\n",
        "        return x\n",
        "\n",
        "\n",
        "class MixerBlock(nn.Module):\n",
        "    \"\"\"One Mixer block: alternates token-mixing and channel-mixing MLPs with residual connections.\"\"\"\n",
        "    def __init__(self, num_patches, embed_dim, token_hidden, channel_hidden, drop=0.0):\n",
        "        super().__init__()\n",
        "        self.norm1 = nn.LayerNorm(embed_dim)\n",
        "        self.token_fc1 = nn.Linear(num_patches, token_hidden)\n",
        "        self.token_fc2 = nn.Linear(token_hidden, num_patches)\n",
        "        self.norm2 = nn.LayerNorm(embed_dim)\n",
        "        self.channel_fc1 = nn.Linear(embed_dim, channel_hidden)\n",
        "        self.channel_fc2 = nn.Linear(channel_hidden, embed_dim)\n",
        "        self.dropout = nn.Dropout(drop)\n",
        "\n",
        "    def forward(self, x):\n",
        "        # Token-mixing\n",
        "        y = self.norm1(x)\n",
        "        y = y.permute(0, 2, 1)\n",
        "        y = F.gelu(self.token_fc1(y))\n",
        "        y = self.token_fc2(y)\n",
        "        y = y.permute(0, 2, 1)\n",
        "        x = x + self.dropout(y)\n",
        "        # Channel-mixing\n",
        "        y = self.norm2(x)\n",
        "        y = F.gelu(self.channel_fc1(y))\n",
        "        y = self.channel_fc2(y)\n",
        "        x = x + self.dropout(y)\n",
        "        return x\n",
        "\n",
        "\n",
        "class MLPMixerTiny(nn.Module):\n",
        "    \"\"\"Tiny MLP-Mixer for CIFAR-10 (<1M params).\"\"\"\n",
        "    def __init__(self, img_size=32, patch_size=4, in_ch=3, embed_dim=160, num_blocks=6,\n",
        "                 token_hidden_mul=1.0, channel_hidden_mul=3.0, num_classes=10, drop=0.0):\n",
        "        super().__init__()\n",
        "        self.patch = PatchEmbedding(img_size, patch_size, in_ch, embed_dim)\n",
        "        num_patches = self.patch.num_patches\n",
        "        token_hidden = max(1, int(num_patches * token_hidden_mul))\n",
        "        channel_hidden = max(1, int(embed_dim * channel_hidden_mul))\n",
        "        self.blocks = nn.ModuleList([\n",
        "            MixerBlock(num_patches, embed_dim, token_hidden, channel_hidden, drop)\n",
        "            for _ in range(num_blocks)\n",
        "        ])\n",
        "        self.norm = nn.LayerNorm(embed_dim)\n",
        "        self.head = nn.Linear(embed_dim, num_classes)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.patch(x)\n",
        "        for blk in self.blocks:\n",
        "            x = blk(x)\n",
        "        x = self.norm(x)\n",
        "        x = x.mean(dim=1)\n",
        "        x = self.head(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "Oy6C12f3l3jp"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Utilities"
      ],
      "metadata": {
        "id": "H5I5XIGKmBHq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def count_parameters(model: nn.Module) -> int:\n",
        "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
        "\n",
        "\n",
        "def mixup_data(x, y, alpha=1.0, device='cuda'):\n",
        "    if alpha <= 0:\n",
        "        return x, y, y, 1.0\n",
        "    lam = np.random.beta(alpha, alpha)\n",
        "    batch_size = x.size(0)\n",
        "    index = torch.randperm(batch_size, device=device)\n",
        "    mixed_x = lam * x + (1 - lam) * x[index]\n",
        "    y_a, y_b = y, y[index]\n",
        "    return mixed_x, y_a, y_b, lam\n",
        "\n",
        "\n",
        "class ModelEMA:\n",
        "    \"\"\"EMA robust to torch.compile() via deepcopy and _orig_mod unwrapping.\"\"\"\n",
        "    def __init__(self, model, decay=0.9999, device='cuda'):\n",
        "        self.decay = decay\n",
        "        self.ema = self._clone_model(model).to(device)\n",
        "        for p in self.ema.parameters():\n",
        "            p.requires_grad_(False)\n",
        "\n",
        "    def _clone_model(self, model):\n",
        "        if hasattr(model, \"_orig_mod\"):\n",
        "            model = model._orig_mod\n",
        "        m = copy.deepcopy(model)\n",
        "        m.eval()\n",
        "        return m\n",
        "\n",
        "    def update(self, model):\n",
        "        with torch.no_grad():\n",
        "            model_state = model._orig_mod.state_dict() if hasattr(model, \"_orig_mod\") else model.state_dict()\n",
        "            ema_state = self.ema.state_dict()\n",
        "            for k, ema_param in ema_state.items():\n",
        "                model_param = model_state[k]\n",
        "                if ema_param.dtype.is_floating_point:\n",
        "                    ema_param.mul_(self.decay).add_(model_param.detach(), alpha=1.0 - self.decay)\n",
        "                else:\n",
        "                    ema_param.copy_(model_param.detach())"
      ],
      "metadata": {
        "id": "ssh7YrD_mEnk"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training & Evaluation"
      ],
      "metadata": {
        "id": "cynY9182mQvh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def train_one_epoch(model, ema, loader, optimizer, device, epoch, args):\n",
        "    model.train()\n",
        "    total_loss = 0.0\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    pbar = tqdm(loader, desc=f\"Epoch {epoch+1:03d} [Train]\", leave=False)\n",
        "    for x, y in pbar:\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        y = y.to(device, non_blocking=True)\n",
        "\n",
        "        if args.mixup:\n",
        "            x, y_a, y_b, lam = mixup_data(x, y, alpha=args.mixup_alpha, device=device)\n",
        "            outputs = model(x)\n",
        "            loss = lam * F.cross_entropy(outputs, y_a) + (1 - lam) * F.cross_entropy(outputs, y_b)\n",
        "        else:\n",
        "            outputs = model(x)\n",
        "            loss = F.cross_entropy(outputs, y)\n",
        "\n",
        "        optimizer.zero_grad(set_to_none=True)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        if ema is not None:\n",
        "            ema.update(model)\n",
        "\n",
        "        batch_size = x.size(0)\n",
        "        total_loss += loss.item() * batch_size\n",
        "        total += batch_size\n",
        "        _, pred = outputs.max(1)\n",
        "        if args.mixup:\n",
        "            correct += (lam * pred.eq(y_a).sum().item() + (1 - lam) * pred.eq(y_b).sum().item())\n",
        "        else:\n",
        "            correct += pred.eq(y).sum().item()\n",
        "\n",
        "        pbar.set_postfix({'loss': f\"{loss.item():.4f}\", 'acc': f\"{100. * correct / total:.2f}%\"})\n",
        "\n",
        "    return total_loss / total, 100.0 * correct / total\n",
        "\n",
        "\n",
        "@torch.no_grad()\n",
        "def evaluate(model, loader, device, compute_metrics=False):\n",
        "    model.eval()\n",
        "    total = 0\n",
        "    correct = 0\n",
        "    total_loss = 0.0\n",
        "    all_preds, all_labels = [], []\n",
        "\n",
        "    pbar = tqdm(loader, desc=\"Evaluating\", leave=False)\n",
        "    for x, y in pbar:\n",
        "        x = x.to(device, non_blocking=True)\n",
        "        y = y.to(device, non_blocking=True)\n",
        "        out = model(x)\n",
        "        loss = F.cross_entropy(out, y)\n",
        "        total_loss += loss.item() * x.size(0)\n",
        "        total += x.size(0)\n",
        "        _, pred = out.max(1)\n",
        "        correct += pred.eq(y).sum().item()\n",
        "\n",
        "        if compute_metrics:\n",
        "            all_preds.append(pred.cpu())\n",
        "            all_labels.append(y.cpu())\n",
        "        pbar.set_postfix({'loss': f\"{loss.item():.4f}\", 'acc': f\"{100. * correct / total:.2f}%\"})\n",
        "\n",
        "    avg_loss = total_loss / total\n",
        "    acc = 100.0 * correct / total\n",
        "    if compute_metrics:\n",
        "        return avg_loss, acc, torch.cat(all_preds), torch.cat(all_labels)\n",
        "    return avg_loss, acc"
      ],
      "metadata": {
        "id": "sLfjCGX7mWZB"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Metrics & Visualization"
      ],
      "metadata": {
        "id": "eMNMbYRHmdnx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def compute_final_metrics(preds, labels, num_classes=10):\n",
        "    preds_np = preds.numpy()\n",
        "    labels_np = labels.numpy()\n",
        "    precision, recall, f1, _ = precision_recall_fscore_support(\n",
        "        labels_np, preds_np, labels=list(range(num_classes)), zero_division=0\n",
        "    )\n",
        "    cm = confusion_matrix(labels_np, preds_np, labels=list(range(num_classes)))\n",
        "    return {\n",
        "        'precision_per_class': precision,\n",
        "        'recall_per_class': recall,\n",
        "        'f1_per_class': f1,\n",
        "        'precision_macro': precision.mean(),\n",
        "        'recall_macro': recall.mean(),\n",
        "        'f1_macro': f1.mean(),\n",
        "        'confusion_matrix': cm\n",
        "    }\n",
        "\n",
        "\n",
        "def plot_confusion_matrix(cm, class_names, save_path=None):\n",
        "    if not MATPLOTLIB_AVAILABLE:\n",
        "        return\n",
        "    plt.figure(figsize=(8, 6))\n",
        "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues',\n",
        "                xticklabels=class_names, yticklabels=class_names)\n",
        "    plt.xlabel('Predicted')\n",
        "    plt.ylabel('True')\n",
        "    plt.title('Confusion Matrix')\n",
        "    plt.tight_layout()\n",
        "    if save_path:\n",
        "        plt.savefig(save_path, dpi=150, bbox_inches='tight')\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "a_duWskLmke0"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Main"
      ],
      "metadata": {
        "id": "p6JQr_FxmsRJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    parser = argparse.ArgumentParser(description=\"Train MLPMixerTiny on CIFAR-10\")\n",
        "    parser.add_argument('--epochs', type=int, default=200)\n",
        "    parser.add_argument('--batch-size', type=int, default=128)\n",
        "    parser.add_argument('--lr', type=float, default=1e-3)\n",
        "    parser.add_argument('--weight-decay', type=float, default=1e-4)\n",
        "    parser.add_argument('--device', type=str, default='cuda' if torch.cuda.is_available() else 'cpu')\n",
        "    parser.add_argument('--mixup', action='store_true')\n",
        "    parser.add_argument('--mixup-alpha', type=float, default=0.8)\n",
        "    parser.add_argument('--seed', type=int, default=42)\n",
        "    parser.add_argument('--save-dir', type=str, default='./checkpoints')\n",
        "    parser.add_argument('--resume', type=str, default='')\n",
        "    args = parser.parse_args(args=[])\n",
        "\n",
        "    # Reproducibility\n",
        "    torch.manual_seed(args.seed)\n",
        "    np.random.seed(args.seed)\n",
        "    random.seed(args.seed)\n",
        "    if torch.cuda.is_available():\n",
        "        torch.cuda.manual_seed_all(args.seed)\n",
        "        torch.backends.cudnn.deterministic = True\n",
        "        torch.backends.cudnn.benchmark = False\n",
        "\n",
        "    device = torch.device(args.device)\n",
        "    print(\"Using device:\", device)\n",
        "\n",
        "    # ----------------------------- TF32 CONFIG (NEW API, PyTorch >= 2.9) -----------------------------\n",
        "    if torch.cuda.is_available():\n",
        "        cap = torch.cuda.get_device_capability()\n",
        "        if cap >= (8, 0):\n",
        "            torch.backends.fp32_precision = \"tf32\"\n",
        "            torch.backends.cuda.matmul.fp32_precision = \"tf32\"\n",
        "            torch.backends.cudnn.fp32_precision = \"tf32\"\n",
        "            torch.backends.cudnn.conv.fp32_precision = \"tf32\"\n",
        "            print(\"TF32 enabled via new API (GPU capability:\", cap, \")\")\n",
        "        else:\n",
        "            torch.backends.fp32_precision = \"ieee\"\n",
        "            torch.backends.cuda.matmul.fp32_precision = \"ieee\"\n",
        "            torch.backends.cudnn.fp32_precision = \"ieee\"\n",
        "            torch.backends.cudnn.conv.fp32_precision = \"ieee\"\n",
        "            print(\"IEEE FP32 enforced (GPU capability:\", cap, \")\")\n",
        "    else:\n",
        "        print(\"CUDA not available ‚Äî running on CPU\")\n",
        "\n",
        "    # Suppress non-critical max_autotune_gemm warning\n",
        "    warnings.filterwarnings(\"ignore\", message=\"Not enough SMs to use max_autotune_gemm mode\")\n",
        "\n",
        "    # ----------------------------- DATA -----------------------------\n",
        "    print(\"Loading CIFAR-10 dataset...\")\n",
        "    transform_train = transforms.Compose([\n",
        "        transforms.RandomCrop(32, padding=4),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.AutoAugment(policy=transforms.AutoAugmentPolicy.CIFAR10),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "    ])\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "    ])\n",
        "\n",
        "    trainset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transform_train)\n",
        "    testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "    class_names = testset.classes\n",
        "\n",
        "    # Use num_workers=2 to avoid DataLoader warning on smaller systems\n",
        "    train_loader = DataLoader(trainset, batch_size=args.batch_size, shuffle=True,\n",
        "                              num_workers=2, pin_memory=True)\n",
        "    val_loader = DataLoader(testset, batch_size=256, shuffle=False,\n",
        "                            num_workers=2, pin_memory=True)\n",
        "\n",
        "    # ----------------------------- MODEL -----------------------------\n",
        "    print(\"Building MLPMixerTiny...\")\n",
        "    model = MLPMixerTiny(\n",
        "        img_size=32, patch_size=4, in_ch=3, embed_dim=160,\n",
        "        num_blocks=6, token_hidden_mul=1.0, channel_hidden_mul=3.0,\n",
        "        num_classes=10, drop=0.0\n",
        "    ).to(device)\n",
        "\n",
        "    total_params = count_parameters(model)\n",
        "    print(\"Model built. Trainable params:\", f\"{total_params:,}\", \"(< 1M)\")\n",
        "\n",
        "    # torch.compile (with graceful fallback)\n",
        "    if hasattr(torch, 'compile') and device.type == 'cuda':\n",
        "        try:\n",
        "            model = torch.compile(model, mode=\"reduce-overhead\")\n",
        "            print(\"Model compiled (mode='reduce-overhead')\")\n",
        "        except Exception as e:\n",
        "            print(\"[Warning] torch.compile failed:\", e, \". Using eager mode.\")\n",
        "\n",
        "    # ----------------------------- OPTIMIZER & SCHEDULER -----------------------------\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=args.lr, weight_decay=args.weight_decay)\n",
        "\n",
        "    def lr_lambda(epoch):\n",
        "        warmup = 10\n",
        "        if epoch < warmup:\n",
        "            return (epoch + 1) / max(1, warmup)\n",
        "        return 0.5 * (1.0 + math.cos(math.pi * (epoch - warmup) / (args.epochs - warmup)))\n",
        "    scheduler = optim.lr_scheduler.LambdaLR(optimizer, lr_lambda)\n",
        "\n",
        "    # ----------------------------- EMA & CHECKPOINT -----------------------------\n",
        "    ema = ModelEMA(model, decay=0.9999, device=device)\n",
        "    os.makedirs(args.save_dir, exist_ok=True)\n",
        "    dataset_name = \"cifar10\"\n",
        "    best_model_path = os.path.join(args.save_dir, f\"{dataset_name}_best.pt\")\n",
        "\n",
        "    # ----------------------------- RESUME -----------------------------\n",
        "    start_epoch, best_acc = 0, 0.0\n",
        "    if args.resume:\n",
        "        if os.path.isfile(args.resume):\n",
        "            print(\"Resuming from:\", args.resume)\n",
        "            ckpt = torch.load(args.resume, map_location=device)\n",
        "            model.load_state_dict(ckpt['model_state'])\n",
        "            optimizer.load_state_dict(ckpt['optimizer'])\n",
        "            scheduler.load_state_dict(ckpt.get('scheduler', {}))\n",
        "            start_epoch = ckpt.get('epoch', 0)\n",
        "            best_acc = ckpt.get('val_acc', 0.0)\n",
        "            print(\"Resuming from epoch\", start_epoch, \", best val acc:\", f\"{best_acc:.2f}%\")\n",
        "            ema = ModelEMA(model, decay=0.9999, device=device)\n",
        "        else:\n",
        "            print(\"[Error] Checkpoint not found:\", args.resume)\n",
        "            return\n",
        "\n",
        "    # ----------------------------- TRAINING LOOP -----------------------------\n",
        "    print(\"\\nStarting training from epoch\", start_epoch+1, \"to\", args.epochs, \"...\")\n",
        "    for epoch in range(start_epoch, args.epochs):\n",
        "        train_loss, train_acc = train_one_epoch(model, ema, train_loader, optimizer, device, epoch, args)\n",
        "        scheduler.step()\n",
        "\n",
        "        eval_model = ema.ema if ema is not None else model\n",
        "        val_loss, val_acc = evaluate(eval_model, val_loader, device)\n",
        "\n",
        "        lr = scheduler.get_last_lr()[0]\n",
        "        print(f\"Epoch {epoch+1:03d} | \"\n",
        "              f\"Train Loss {train_loss:.4f} Acc {train_acc:.2f}% | \"\n",
        "              f\"Val Loss {val_loss:.4f} Acc {val_acc:.2f}% | \"\n",
        "              f\"LR {lr:.2e}\")\n",
        "\n",
        "        if val_acc > best_acc:\n",
        "            best_acc = val_acc\n",
        "            torch.save({\n",
        "                'epoch': epoch + 1,\n",
        "                'model_state': eval_model.state_dict(),\n",
        "                'optimizer': optimizer.state_dict(),\n",
        "                'scheduler': scheduler.state_dict(),\n",
        "                'val_acc': best_acc,\n",
        "                'args': vars(args)\n",
        "            }, best_model_path)\n",
        "            print(\"New best model saved:\", best_model_path, \"(Val Acc:\", f\"{best_acc:.2f}%)\")\n",
        "\n",
        "    print(\"\\nTraining finished. Best validation accuracy:\", f\"{best_acc:.2f}%\")"
      ],
      "metadata": {
        "id": "FmDVUtl-muuI"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final Evaluation"
      ],
      "metadata": {
        "id": "zyzuEsDtnNjw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def evaluate_checkpoint(\n",
        "    checkpoint_path: str,\n",
        "    device: torch.device,\n",
        "    dataset_name: str = \"cifar10\",\n",
        "    save_dir: str = \"./checkpoints\",\n",
        "    batch_size: int = 256,\n",
        "    num_workers: int = 2,\n",
        "    class_names: list = None,\n",
        "    plot_cm: bool = True\n",
        ") -> dict:\n",
        "    \"\"\"\n",
        "    Standalone function to evaluate a saved checkpoint on CIFAR-10 test set.\n",
        "\n",
        "    Args:\n",
        "        checkpoint_path (str): Path to the .pt checkpoint file.\n",
        "        device (torch.device): Device to run evaluation on.\n",
        "        dataset_name (str): Name for labeling outputs (e.g., 'cifar10').\n",
        "        save_dir (str): Directory to save metrics and plots.\n",
        "        batch_size (int): Batch size for DataLoader.\n",
        "        num_workers (int): Workers for DataLoader.\n",
        "        class_names (list, optional): List of class names. Defaults to CIFAR-10.\n",
        "        plot_cm (bool): Whether to generate and save confusion matrix plot.\n",
        "\n",
        "    Returns:\n",
        "        dict: Dictionary containing test loss, accuracy, and full metrics.\n",
        "    \"\"\"\n",
        "    # ----------------------------- DEFAULTS -----------------------------\n",
        "    if class_names is None:\n",
        "        class_names = ['airplane', 'automobile', 'bird', 'cat', 'deer',\n",
        "                       'dog', 'frog', 'horse', 'ship', 'truck']\n",
        "\n",
        "    # ----------------------------- DATA -----------------------------\n",
        "    transform_test = transforms.Compose([\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "    ])\n",
        "    testset = datasets.CIFAR10(root='./data', train=False, download=False, transform=transform_test)\n",
        "    test_loader = DataLoader(testset, batch_size=batch_size, shuffle=False,\n",
        "                             num_workers=num_workers, pin_memory=True)\n",
        "\n",
        "    # ----------------------------- MODEL (RAW, UNCOMPILED) -----------------------------\n",
        "    print(\"Building raw model for evaluation...\")\n",
        "    model = MLPMixerTiny(\n",
        "        img_size=32, patch_size=4, in_ch=3, embed_dim=160,\n",
        "        num_blocks=6, token_hidden_mul=1.0, channel_hidden_mul=3.0,\n",
        "        num_classes=10, drop=0.0\n",
        "    ).to(device)\n",
        "\n",
        "    # Load checkpoint\n",
        "    print(f\"Loading checkpoint: {checkpoint_path}\")\n",
        "    ckpt = torch.load(checkpoint_path, map_location=device)\n",
        "    model.load_state_dict(ckpt['model_state'])\n",
        "    model.eval()\n",
        "\n",
        "    # Optional: compile for faster inference (safe fallback)\n",
        "    if hasattr(torch, 'compile') and device.type == 'cuda':\n",
        "        try:\n",
        "            model = torch.compile(model, mode=\"default\")\n",
        "            print(\"Model compiled for inference (mode='default').\")\n",
        "        except Exception as e:\n",
        "            print(\"[Warning] torch.compile failed during eval:\", e)\n",
        "\n",
        "    # ----------------------------- EVALUATION -----------------------------\n",
        "    print(\"Running evaluation on test set...\")\n",
        "    test_loss, test_acc, preds, labels = evaluate(model, test_loader, device, compute_metrics=True)\n",
        "    print(f\"\\n‚úÖ Test Results ‚Üí Loss: {test_loss:.4f}, Accuracy: {test_acc:.2f}%\")\n",
        "\n",
        "    # ----------------------------- METRICS -----------------------------\n",
        "    metrics = compute_final_metrics(preds, labels, num_classes=10)\n",
        "\n",
        "    # ----------------------------- SAVE RESULTS -----------------------------\n",
        "    os.makedirs(save_dir, exist_ok=True)\n",
        "\n",
        "    # Text metrics\n",
        "    metrics_path = os.path.join(save_dir, f\"{dataset_name}_final_metrics.txt\")\n",
        "    with open(metrics_path, 'w') as f:\n",
        "        f.write(f\"Checkpoint: {checkpoint_path}\\n\")\n",
        "        f.write(f\"Dataset: {dataset_name}\\n\")\n",
        "        f.write(f\"Test Accuracy: {test_acc:.2f}%\\n\")\n",
        "        f.write(f\"Test Loss: {test_loss:.4f}\\n\\n\")\n",
        "\n",
        "        f.write(f\"Macro Precision: {metrics['precision_macro']:.4f}\\n\")\n",
        "        f.write(f\"Macro Recall:    {metrics['recall_macro']:.4f}\\n\")\n",
        "        f.write(f\"Macro F1:        {metrics['f1_macro']:.4f}\\n\\n\")\n",
        "\n",
        "        f.write(\"Per-class metrics:\\n\")\n",
        "        for i, cls in enumerate(class_names):\n",
        "            p, r, f1 = (\n",
        "                metrics['precision_per_class'][i],\n",
        "                metrics['recall_per_class'][i],\n",
        "                metrics['f1_per_class'][i]\n",
        "            )\n",
        "            f.write(f\"{cls:10}: P={p:.4f}, R={r:.4f}, F1={f1:.4f}\\n\")\n",
        "        f.write(f\"\\nConfusion Matrix:\\n{metrics['confusion_matrix']}\")\n",
        "    print(\"üìù Metrics saved to:\", metrics_path)\n",
        "\n",
        "    # Confusion matrix plot\n",
        "    if plot_cm and MATPLOTLIB_AVAILABLE:\n",
        "        cm_path = os.path.join(save_dir, f\"{dataset_name}_confusion_matrix.png\")\n",
        "        plot_confusion_matrix(metrics['confusion_matrix'], class_names, save_path=cm_path)\n",
        "        print(\"üñºÔ∏è  Confusion matrix saved to:\", cm_path)\n",
        "    elif plot_cm:\n",
        "        print(\"[Info] Skipping confusion matrix plot (matplotlib not available).\")\n",
        "\n",
        "    # Return structured results\n",
        "    results = {\n",
        "        'test_loss': test_loss,\n",
        "        'test_acc': test_acc,\n",
        "        'precision_macro': metrics['precision_macro'],\n",
        "        'recall_macro': metrics['recall_macro'],\n",
        "        'f1_macro': metrics['f1_macro'],\n",
        "        'precision_per_class': metrics['precision_per_class'],\n",
        "        'recall_per_class': metrics['recall_per_class'],\n",
        "        'f1_per_class': metrics['f1_per_class'],\n",
        "        'confusion_matrix': metrics['confusion_matrix'],\n",
        "        'checkpoint_path': checkpoint_path,\n",
        "        'metrics_file': metrics_path,\n",
        "    }\n",
        "    return results"
      ],
      "metadata": {
        "id": "EVJG4Er6ncCP"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "W3S-Cdxrnith"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "DJtuEw7FlZgZ"
      },
      "outputs": [],
      "source": [
        "if __name__ == '__main__':\n",
        "    main()"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Evaluation"
      ],
      "metadata": {
        "id": "SEZtFGarp84I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torchvision import datasets, transforms\n",
        "import os # Import os for path joining\n",
        "\n",
        "# Re-initialize device (was defined in main() scope)\n",
        "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "# Re-create testset to get class_names (was defined in main() scope)\n",
        "transform_test = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize((0.4914, 0.4822, 0.4465), (0.247, 0.243, 0.261))\n",
        "])\n",
        "testset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transform_test)\n",
        "\n",
        "# Define save_dir and checkpoint_path (derived from args in main())\n",
        "save_dir = './checkpoints'\n",
        "dataset_name = \"cifar10\"\n",
        "checkpoint_file = os.path.join(save_dir, f\"{dataset_name}_best.pt\")\n",
        "\n",
        "# ----------------------------- FINAL EVALUATION -----------------------------\n",
        "print(\"\\nFinal evaluation on test set...\")\n",
        "results = evaluate_checkpoint(\n",
        "    checkpoint_path=checkpoint_file,\n",
        "    device=device,\n",
        "    dataset_name=dataset_name,\n",
        "    save_dir=save_dir,\n",
        "    batch_size=256,\n",
        "    class_names=testset.classes  # Now testset.classes is available\n",
        ")\n",
        "print(\"Macro Avg ‚Üí P:\", f\"{results['precision_macro']:.4f},\",\n",
        "      \"R:\", f\"{results['recall_macro']:.4f},\",\n",
        "      \"F1:\", f\"{results['f1_macro']:.4f}\")"
      ],
      "metadata": {
        "id": "kvkD6juPld1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8q8z54QVnt2b"
      },
      "execution_count": 9,
      "outputs": []
    }
  ]
}